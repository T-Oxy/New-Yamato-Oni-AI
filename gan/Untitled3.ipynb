{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-4-bcb78ceb85d9>, line 168)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-bcb78ceb85d9>\"\u001b[0;36m, line \u001b[0;32m168\u001b[0m\n\u001b[0;31m    gen_imgs = self.generator.predict(noise)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "def save_imgs(self, iteration, check_noise, r, c):\n",
    "    noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "    plt.close()\n",
    "\n",
    "def load_imgs(self):\n",
    "    \n",
    "    img_paths = []\n",
    "    labels = []\n",
    "    images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "    for cl_name in self.class_names:\n",
    "        if cl_name == input_img_dir:\n",
    "            img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "            for img_name in img_names:\n",
    "                img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "return (np.array(images), np.array(labels))\n",
    "\n",
    "def get_class_one_hot(self, class_str):\n",
    "    label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "    label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "    return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "                iterations=200000,\n",
    "                batch_size=32,\n",
    "                # save_interval=1000,\n",
    "                save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "                model_interval=5000,\n",
    "                check_noise=check_noise,\n",
    "                r=r,\n",
    "                c=c\n",
    "                )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'better_exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4a8c54b88ab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbetter_exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madvanced_activations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLeakyReLU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'better_exceptions'"
     ]
    }
   ],
   "source": [
    "import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        iterations=200000,\n",
    "        batch_size=32,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-baf1eed66d39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     )\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-baf1eed66d39>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        iterations=200000,\n",
    "        batch_size=32,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-34abb58dc431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-7-34abb58dc431>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "50\n",
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b5ce39d21d8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-b5ce39d21d8e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        print(half_batch)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train.shape[0])\n",
    "        \n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3fc9eaae8f83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-9-3fc9eaae8f83>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train.shape[0])\n",
    "        print(X_train.shape[1])\n",
    "        print(X_train.shape[2])\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-e3dae13bdd61>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-e3dae13bdd61>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    mport better_exceptions\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mport better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_28 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_4 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b13254e2daac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-b13254e2daac>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_35 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_21 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_22 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_23 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_11 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "[]\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3a8cec7f9364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     )\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-3a8cec7f9364>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        print(images)\n",
    "\n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7aaadb854e49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_names' is not defined"
     ]
    }
   ],
   "source": [
    "print(img_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-14-0e675a872b20>, line 204)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-0e675a872b20>\"\u001b[0;36m, line \u001b[0;32m204\u001b[0m\n\u001b[0;31m    for img_name in img_names:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "            print(img_names)\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_24 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_26 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_27 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_12 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_13 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-94552b29bbcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-15-94552b29bbcd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = '/Users/user/Desktop/m31_expt/m31_datasets/'\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "                print(img_names)\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_49 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_28 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_29 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_14 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_15 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-b3c8a33e645e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-16-b3c8a33e645e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/\"\n",
    "input_img_dir = \"all_resize/\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_56 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_35 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-979ed4669c67>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     )\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-979ed4669c67>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/\"\n",
    "input_img_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/all_resize\"\n",
    "save_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_63 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_36 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_64 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_37 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_65 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_38 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_39 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_9 (Reshape)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "/Users/user/Desktop/m31_expt/m31_datasets/all_resize\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'cl_name' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-25e59a4cce3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-18-25e59a4cce3e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mhalf_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-25e59a4cce3e>\u001b[0m in \u001b[0;36mload_imgs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'cl_name' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/\"\n",
    "input_img_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/all_resize\"\n",
    "save_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "    \n",
    "        print(input_img_dir)\n",
    "        print(cl_name)\n",
    "        print(self.class_names)\n",
    "    \n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_70 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_40 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_41 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_42 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_43 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "/Users/user/Desktop/m31_expt/m31_datasets/all_resize\n",
      "['dcgan_v2.py', 'DCGAN_human_w1_img', 'benkei', 'Untitled1.ipynb', 'human_w1', '.DS_Store', 'dcgan_v3.py', 'DCGAN_all_para', 'Untitled3.ipynb', 'Untitled.ipynb', 'human_w1_resize', 'all', 'Untitled2.ipynb', 'untitled.txt', 'dcgan.py', 'resize.py', 'human_w2', 'demon_2', '.ipynb_checkpoints', 'human_m', 'DCGAN_human_w1_para', 'DCGAN_all_img', 'demon', 'all_resize', 'dcgan_w1.py']\n",
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "low >= high",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f21ed7e9d7b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     )\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-f21ed7e9d7b8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Training Discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: low >= high"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/\"\n",
    "input_img_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/all_resize\"\n",
    "save_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "    \n",
    "        print(input_img_dir)\n",
    "        print(self.class_names)\n",
    "    \n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_77 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_44 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_45 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_46 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_80 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_47 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_22 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_81 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_23 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "all_resize\n",
      "['dcgan_v2.py', 'DCGAN_human_w1_img', 'benkei', 'Untitled1.ipynb', 'human_w1', '.DS_Store', 'dcgan_v3.py', 'DCGAN_all_para', 'Untitled3.ipynb', 'Untitled.ipynb', 'human_w1_resize', 'all', 'Untitled2.ipynb', 'untitled.txt', 'dcgan.py', 'resize.py', 'human_w2', 'demon_2', '.ipynb_checkpoints', 'human_m', 'DCGAN_human_w1_para', 'DCGAN_all_img', 'demon', 'all_resize', 'dcgan_w1.py']\n",
      "[[[[ 0.7647059   0.6313726   0.49019608]\n",
      "   [ 0.7882353   0.654902    0.5137255 ]\n",
      "   [ 0.8117647   0.6784314   0.5372549 ]\n",
      "   ...\n",
      "   [ 0.62352943  0.5686275   0.5058824 ]\n",
      "   [ 0.654902    0.6         0.5372549 ]\n",
      "   [ 1.          0.9843137   0.92156863]]\n",
      "\n",
      "  [[ 0.18431373  0.05098039 -0.09019608]\n",
      "   [ 0.2         0.06666667 -0.07450981]\n",
      "   [ 0.21568628  0.08235294 -0.05882353]\n",
      "   ...\n",
      "   [ 0.01176471 -0.04313726 -0.10588235]\n",
      "   [ 0.19215687  0.13725491  0.07450981]\n",
      "   [ 0.7490196   0.69411767  0.6313726 ]]\n",
      "\n",
      "  [[ 0.29411766  0.16078432  0.01960784]\n",
      "   [ 0.3019608   0.16862746  0.02745098]\n",
      "   [ 0.30980393  0.1764706   0.03529412]\n",
      "   ...\n",
      "   [-0.13725491 -0.19215687 -0.25490198]\n",
      "   [ 0.14509805  0.09019608  0.02745098]\n",
      "   [ 0.8039216   0.7490196   0.6862745 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.5686275   0.43529412  0.21568628]\n",
      "   [ 0.41960785  0.3019608   0.07450981]\n",
      "   [ 0.2         0.08235294 -0.14509805]\n",
      "   ...\n",
      "   [ 0.45882353  0.40392157  0.34117648]\n",
      "   [ 0.2         0.12156863  0.10588235]\n",
      "   [-0.05098039 -0.12941177 -0.13725491]]\n",
      "\n",
      "  [[ 0.7176471   0.5529412   0.3882353 ]\n",
      "   [ 0.7647059   0.62352943  0.4509804 ]\n",
      "   [ 0.6784314   0.5529412   0.37254903]\n",
      "   ...\n",
      "   [ 0.6862745   0.6313726   0.5686275 ]\n",
      "   [ 0.54509807  0.46666667  0.4509804 ]\n",
      "   [ 0.3254902   0.24705882  0.23921569]]\n",
      "\n",
      "  [[ 1.          0.96862745  0.81960785]\n",
      "   [ 1.          0.9764706   0.81960785]\n",
      "   [ 1.          0.9607843   0.8039216 ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  0.92941177]\n",
      "   [ 1.          0.9764706   0.9607843 ]\n",
      "   [ 1.          0.9607843   0.9529412 ]]]\n",
      "\n",
      "\n",
      " [[[ 1.          0.9764706   0.9843137 ]\n",
      "   [ 1.          0.9843137   0.99215686]\n",
      "   [ 1.          0.9843137   0.99215686]\n",
      "   ...\n",
      "   [ 0.9764706   0.96862745  1.        ]\n",
      "   [ 0.99215686  0.9843137   1.        ]\n",
      "   [ 1.          0.99215686  1.        ]]\n",
      "\n",
      "  [[ 1.          0.99215686  1.        ]\n",
      "   [ 1.          1.          0.9843137 ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   ...\n",
      "   [ 0.9843137   0.99215686  1.        ]\n",
      "   [ 0.9764706   0.96862745  1.        ]\n",
      "   [ 0.9607843   0.96862745  1.        ]]\n",
      "\n",
      "  [[ 0.9843137   1.          0.9764706 ]\n",
      "   [ 0.9843137   1.          0.9607843 ]\n",
      "   [ 0.9843137   1.          0.9764706 ]\n",
      "   ...\n",
      "   [ 0.9764706   1.          1.        ]\n",
      "   [ 0.9843137   1.          0.99215686]\n",
      "   [ 0.9607843   0.99215686  0.9843137 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.          0.9764706   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   ...\n",
      "   [ 0.99215686  0.99215686  0.9764706 ]\n",
      "   [ 0.99215686  0.99215686  0.9764706 ]\n",
      "   [ 0.99215686  0.99215686  0.9764706 ]]\n",
      "\n",
      "  [[ 1.          0.9843137   0.9843137 ]\n",
      "   [ 1.          0.9764706   0.9764706 ]\n",
      "   [ 1.          1.          0.9843137 ]\n",
      "   ...\n",
      "   [ 0.99215686  0.99215686  1.        ]\n",
      "   [ 0.99215686  0.99215686  1.        ]\n",
      "   [ 0.99215686  0.99215686  1.        ]]\n",
      "\n",
      "  [[ 1.          0.9843137   0.9607843 ]\n",
      "   [ 1.          0.99215686  0.9607843 ]\n",
      "   [ 1.          1.          0.9607843 ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.9529412   1.          1.        ]\n",
      "   [ 0.9529412   1.          1.        ]\n",
      "   [ 0.96862745  1.          1.        ]\n",
      "   ...\n",
      "   [ 0.9764706   1.          1.        ]\n",
      "   [ 0.9764706   1.          1.        ]\n",
      "   [ 0.9764706   1.          1.        ]]\n",
      "\n",
      "  [[ 0.96862745  1.          1.        ]\n",
      "   [ 0.96862745  1.          1.        ]\n",
      "   [ 0.9764706   1.          1.        ]\n",
      "   ...\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]]\n",
      "\n",
      "  [[ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   ...\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.96862745  1.        ]\n",
      "   [ 1.          0.96862745  1.        ]]\n",
      "\n",
      "  [[ 0.9764706   1.          0.96862745]\n",
      "   [ 0.9764706   1.          0.96862745]\n",
      "   [ 0.9764706   1.          0.96862745]\n",
      "   ...\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9764706   1.        ]\n",
      "   [ 1.          0.96862745  1.        ]]\n",
      "\n",
      "  [[ 0.9529412   1.          0.9607843 ]\n",
      "   [ 0.9529412   1.          0.9607843 ]\n",
      "   [ 0.9529412   1.          0.9607843 ]\n",
      "   ...\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.96862745  1.        ]\n",
      "   [ 1.          0.96862745  1.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.4745098   0.3647059   0.13725491]\n",
      "   [ 0.49019608  0.38039216  0.15294118]\n",
      "   [ 0.5058824   0.39607844  0.18431373]\n",
      "   ...\n",
      "   [ 0.49019608  0.40392157  0.24705882]\n",
      "   [ 0.48235294  0.39607844  0.23921569]\n",
      "   [ 0.48235294  0.39607844  0.23921569]]\n",
      "\n",
      "  [[ 0.49019608  0.38039216  0.15294118]\n",
      "   [ 0.49803922  0.3882353   0.16078432]\n",
      "   [ 0.5137255   0.40392157  0.19215687]\n",
      "   ...\n",
      "   [ 0.4745098   0.3882353   0.23137255]\n",
      "   [ 0.4745098   0.3882353   0.23137255]\n",
      "   [ 0.4745098   0.3882353   0.23137255]]\n",
      "\n",
      "  [[ 0.5058824   0.39607844  0.18431373]\n",
      "   [ 0.5137255   0.40392157  0.19215687]\n",
      "   [ 0.52156866  0.4117647   0.2       ]\n",
      "   ...\n",
      "   [ 0.49019608  0.40392157  0.24705882]\n",
      "   [ 0.49019608  0.40392157  0.24705882]\n",
      "   [ 0.49019608  0.40392157  0.24705882]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.30980393  0.25490198  0.11372549]\n",
      "   [ 0.34901962  0.29411766  0.15294118]\n",
      "   [ 0.25490198  0.19215687  0.09019608]\n",
      "   ...\n",
      "   [-0.5764706  -0.6        -0.6392157 ]\n",
      "   [-0.6784314  -0.7176471  -0.7490196 ]\n",
      "   [-0.8039216  -0.84313726 -0.8901961 ]]\n",
      "\n",
      "  [[ 0.3254902   0.27058825  0.12941177]\n",
      "   [ 0.39607844  0.34117648  0.2       ]\n",
      "   [ 0.23137255  0.16862746  0.06666667]\n",
      "   ...\n",
      "   [-0.54509807 -0.5764706  -0.6       ]\n",
      "   [-0.58431375 -0.62352943 -0.64705884]\n",
      "   [-0.7019608  -0.7411765  -0.77254903]]\n",
      "\n",
      "  [[ 0.3254902   0.27058825  0.12941177]\n",
      "   [ 0.4117647   0.35686275  0.21568628]\n",
      "   [ 0.20784314  0.14509805  0.04313726]\n",
      "   ...\n",
      "   [-0.6627451  -0.67058825 -0.6862745 ]\n",
      "   [-0.58431375 -0.62352943 -0.64705884]\n",
      "   [-0.49019608 -0.5294118  -0.5529412 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.9764706   1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 0.99215686  1.          0.9843137 ]\n",
      "   [ 0.96862745  1.          0.96862745]\n",
      "   [ 0.9529412   1.          0.96862745]]\n",
      "\n",
      "  [[ 0.9764706   1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 0.99215686  1.          0.9843137 ]\n",
      "   [ 0.96862745  1.          0.96862745]\n",
      "   [ 0.9529412   1.          0.96862745]]\n",
      "\n",
      "  [[ 0.9764706   1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 0.99215686  1.          0.9843137 ]\n",
      "   [ 0.96862745  1.          0.96862745]\n",
      "   [ 0.9529412   1.          0.96862745]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]]\n",
      "\n",
      "  [[ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]]\n",
      "\n",
      "  [[ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]]]\n",
      "\n",
      "\n",
      " [[[ 0.9764706   1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]]\n",
      "\n",
      "  [[ 0.9764706   1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]]\n",
      "\n",
      "  [[ 0.9764706   1.          1.        ]\n",
      "   [ 0.99215686  1.          1.        ]\n",
      "   [ 1.          1.          1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.99215686  1.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9764706   1.        ]]\n",
      "\n",
      "  [[ 1.          0.9764706   1.        ]\n",
      "   [ 1.          0.9764706   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9764706   1.        ]]\n",
      "\n",
      "  [[ 1.          0.9764706   1.        ]\n",
      "   [ 1.          0.9764706   1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   ...\n",
      "   [ 1.          0.99215686  1.        ]\n",
      "   [ 1.          0.9843137   1.        ]\n",
      "   [ 1.          0.9764706   1.        ]]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 1.879261, acc.: 21.00%] [G loss: 0.583540]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dcgan_v3_img/0.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-03ad91089e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     )\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-03ad91089e11>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msave_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-03ad91089e11>\u001b[0m in \u001b[0;36msave_imgs\u001b[0;34m(self, iteration, check_noise, r, c)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m                 \u001b[0mcnt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'%d.png'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;31m# fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2092\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m                     \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m                 _png.write_png(renderer._renderer, fh,\n\u001b[1;32m    532\u001b[0m                                self.figure.dpi, metadata=metadata)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mopen_file_cm\u001b[0;34m(path_or_file, mode, encoding)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mopen_file_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;34mr\"\"\"Pass through file objects and context-manage `.PathLike`\\s.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m     \u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_filehandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36mto_filehandle\u001b[0;34m(fname, flag, return_opened, encoding)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbz2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBZ2File\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seek'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dcgan_v3_img/0.png'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/\"\n",
    "input_img_dir = \"all_resize\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        \n",
    "        print(X_train)\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "    \n",
    "        print(input_img_dir)\n",
    "        print(self.class_names)\n",
    "    \n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_84 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_48 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_49 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_50 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_12 (Reshape)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_24 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_25 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.879261, acc.: 21.00%] [G loss: 0.583540]\n",
      "Generating interpolations...\n",
      "1 [D loss: 1.112467, acc.: 50.00%] [G loss: 0.853523]\n",
      "2 [D loss: 0.728996, acc.: 60.00%] [G loss: 0.742441]\n",
      "3 [D loss: 0.531992, acc.: 74.00%] [G loss: 0.473861]\n",
      "4 [D loss: 0.311673, acc.: 88.00%] [G loss: 0.222770]\n"
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/\"\n",
    "input_img_dir = \"all_resize\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "    \n",
    "    #print(input_img_dir)\n",
    "    #print(self.class_names)\n",
    "    \n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        #iterations=200000,\n",
    "        iterations=5,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_91 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 33, 33, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 33, 33, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 17, 17, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 17, 17, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 17, 17, 256)       295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)   (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 17, 17, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 73984)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 73985     \n",
      "=================================================================\n",
      "Total params: 463,169\n",
      "Trainable params: 462,785\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 131072)            13238272  \n",
      "_________________________________________________________________\n",
      "reshape_13 (Reshape)         (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_26 (UpSampling (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_27 (UpSampling (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_96 (Conv2D)           (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv2d_97 (Conv2D)           (None, 128, 128, 3)       1731      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 128, 128, 3)       0         \n",
      "=================================================================\n",
      "Total params: 13,462,659\n",
      "Trainable params: 13,462,019\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.879261, acc.: 21.00%] [G loss: 0.583540]\n",
      "Generating interpolations...\n",
      "1 [D loss: 1.112467, acc.: 50.00%] [G loss: 0.853523]\n",
      "2 [D loss: 0.728996, acc.: 60.00%] [G loss: 0.742441]\n",
      "3 [D loss: 0.531992, acc.: 74.00%] [G loss: 0.473861]\n",
      "4 [D loss: 0.311673, acc.: 88.00%] [G loss: 0.222766]\n",
      "5 [D loss: 0.161819, acc.: 97.00%] [G loss: 0.087087]\n",
      "6 [D loss: 0.156207, acc.: 99.00%] [G loss: 0.023223]\n",
      "7 [D loss: 0.092341, acc.: 100.00%] [G loss: 0.010777]\n",
      "8 [D loss: 0.126678, acc.: 98.00%] [G loss: 0.002268]\n",
      "9 [D loss: 0.100400, acc.: 99.00%] [G loss: 0.000950]\n",
      "10 [D loss: 0.098285, acc.: 99.00%] [G loss: 0.000359]\n",
      "11 [D loss: 0.090426, acc.: 98.00%] [G loss: 0.000449]\n",
      "12 [D loss: 0.123784, acc.: 98.00%] [G loss: 0.000124]\n",
      "13 [D loss: 0.060595, acc.: 100.00%] [G loss: 0.000116]\n",
      "14 [D loss: 0.065147, acc.: 100.00%] [G loss: 0.000045]\n",
      "15 [D loss: 0.034199, acc.: 100.00%] [G loss: 0.000118]\n",
      "16 [D loss: 0.038771, acc.: 100.00%] [G loss: 0.000102]\n",
      "17 [D loss: 0.033965, acc.: 100.00%] [G loss: 0.000328]\n",
      "18 [D loss: 0.041994, acc.: 100.00%] [G loss: 0.000535]\n",
      "19 [D loss: 0.040113, acc.: 100.00%] [G loss: 0.001209]\n",
      "20 [D loss: 0.145175, acc.: 99.00%] [G loss: 0.001895]\n",
      "21 [D loss: 0.015981, acc.: 100.00%] [G loss: 0.011581]\n",
      "22 [D loss: 0.054238, acc.: 100.00%] [G loss: 0.018111]\n",
      "23 [D loss: 0.143630, acc.: 96.00%] [G loss: 0.027490]\n",
      "24 [D loss: 0.093897, acc.: 98.00%] [G loss: 0.063628]\n",
      "25 [D loss: 0.269299, acc.: 89.00%] [G loss: 0.724805]\n",
      "26 [D loss: 0.920129, acc.: 51.00%] [G loss: 3.187811]\n",
      "27 [D loss: 0.725734, acc.: 67.00%] [G loss: 0.000727]\n",
      "28 [D loss: 0.426776, acc.: 76.00%] [G loss: 1.170975]\n",
      "29 [D loss: 0.150667, acc.: 93.00%] [G loss: 1.040972]\n",
      "30 [D loss: 0.196256, acc.: 93.00%] [G loss: 0.062557]\n",
      "31 [D loss: 0.175047, acc.: 92.00%] [G loss: 0.404125]\n",
      "32 [D loss: 0.045376, acc.: 100.00%] [G loss: 0.576624]\n",
      "33 [D loss: 0.372702, acc.: 78.00%] [G loss: 3.665561]\n",
      "34 [D loss: 0.331929, acc.: 89.00%] [G loss: 0.247195]\n",
      "35 [D loss: 0.063417, acc.: 100.00%] [G loss: 0.828935]\n",
      "36 [D loss: 0.066621, acc.: 98.00%] [G loss: 1.261915]\n",
      "37 [D loss: 0.037842, acc.: 100.00%] [G loss: 0.894202]\n",
      "38 [D loss: 0.064060, acc.: 100.00%] [G loss: 1.495384]\n",
      "39 [D loss: 0.012317, acc.: 100.00%] [G loss: 1.522063]\n",
      "40 [D loss: 0.034620, acc.: 100.00%] [G loss: 0.936072]\n",
      "41 [D loss: 0.061016, acc.: 99.00%] [G loss: 1.231299]\n",
      "42 [D loss: 0.025590, acc.: 100.00%] [G loss: 1.368883]\n",
      "43 [D loss: 0.019698, acc.: 100.00%] [G loss: 1.251945]\n",
      "44 [D loss: 0.195456, acc.: 95.00%] [G loss: 1.897904]\n",
      "45 [D loss: 0.026258, acc.: 99.00%] [G loss: 1.914366]\n",
      "46 [D loss: 0.097335, acc.: 96.00%] [G loss: 0.100822]\n",
      "47 [D loss: 0.075236, acc.: 100.00%] [G loss: 0.891446]\n",
      "48 [D loss: 0.001261, acc.: 100.00%] [G loss: 1.617909]\n",
      "49 [D loss: 0.011965, acc.: 100.00%] [G loss: 0.584630]\n",
      "50 [D loss: 0.005687, acc.: 100.00%] [G loss: 0.306858]\n",
      "Generating interpolations...\n",
      "51 [D loss: 0.038806, acc.: 99.00%] [G loss: 0.056421]\n",
      "52 [D loss: 0.008256, acc.: 100.00%] [G loss: 0.066914]\n",
      "53 [D loss: 0.006180, acc.: 100.00%] [G loss: 0.094357]\n",
      "54 [D loss: 0.005405, acc.: 100.00%] [G loss: 0.092134]\n",
      "55 [D loss: 0.002601, acc.: 100.00%] [G loss: 0.078619]\n",
      "56 [D loss: 0.003223, acc.: 100.00%] [G loss: 0.089294]\n",
      "57 [D loss: 0.023214, acc.: 100.00%] [G loss: 0.027238]\n",
      "58 [D loss: 0.008203, acc.: 100.00%] [G loss: 0.020066]\n",
      "59 [D loss: 0.004106, acc.: 100.00%] [G loss: 0.039562]\n",
      "60 [D loss: 0.002509, acc.: 100.00%] [G loss: 0.024297]\n",
      "61 [D loss: 0.002640, acc.: 100.00%] [G loss: 0.040854]\n",
      "62 [D loss: 0.001372, acc.: 100.00%] [G loss: 0.025523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 [D loss: 0.006963, acc.: 100.00%] [G loss: 0.045495]\n",
      "64 [D loss: 0.005383, acc.: 100.00%] [G loss: 0.028441]\n",
      "65 [D loss: 0.000965, acc.: 100.00%] [G loss: 0.026333]\n",
      "66 [D loss: 0.002376, acc.: 100.00%] [G loss: 0.029177]\n",
      "67 [D loss: 0.001216, acc.: 100.00%] [G loss: 0.042938]\n",
      "68 [D loss: 0.001532, acc.: 100.00%] [G loss: 0.031579]\n",
      "69 [D loss: 0.002603, acc.: 100.00%] [G loss: 0.034535]\n",
      "70 [D loss: 0.000752, acc.: 100.00%] [G loss: 0.030513]\n",
      "71 [D loss: 0.001431, acc.: 100.00%] [G loss: 0.037650]\n",
      "72 [D loss: 0.001689, acc.: 100.00%] [G loss: 0.036312]\n",
      "73 [D loss: 0.000551, acc.: 100.00%] [G loss: 0.028682]\n",
      "74 [D loss: 0.001027, acc.: 100.00%] [G loss: 0.028941]\n",
      "75 [D loss: 0.000515, acc.: 100.00%] [G loss: 0.034042]\n",
      "76 [D loss: 0.000690, acc.: 100.00%] [G loss: 0.020065]\n",
      "77 [D loss: 0.001061, acc.: 100.00%] [G loss: 0.034625]\n",
      "78 [D loss: 0.001061, acc.: 100.00%] [G loss: 0.031792]\n",
      "79 [D loss: 0.002510, acc.: 100.00%] [G loss: 0.042073]\n",
      "80 [D loss: 0.002634, acc.: 100.00%] [G loss: 0.027588]\n",
      "81 [D loss: 0.000494, acc.: 100.00%] [G loss: 0.018408]\n",
      "82 [D loss: 0.000960, acc.: 100.00%] [G loss: 0.020350]\n",
      "83 [D loss: 0.000858, acc.: 100.00%] [G loss: 0.020062]\n",
      "84 [D loss: 0.000817, acc.: 100.00%] [G loss: 0.020553]\n",
      "85 [D loss: 0.001685, acc.: 100.00%] [G loss: 0.025130]\n",
      "86 [D loss: 0.000475, acc.: 100.00%] [G loss: 0.026182]\n",
      "87 [D loss: 0.000404, acc.: 100.00%] [G loss: 0.013306]\n",
      "88 [D loss: 0.001308, acc.: 100.00%] [G loss: 0.018872]\n",
      "89 [D loss: 0.001257, acc.: 100.00%] [G loss: 0.020993]\n",
      "90 [D loss: 0.000693, acc.: 100.00%] [G loss: 0.025581]\n",
      "91 [D loss: 0.000618, acc.: 100.00%] [G loss: 0.020152]\n",
      "92 [D loss: 0.000615, acc.: 100.00%] [G loss: 0.017630]\n",
      "93 [D loss: 0.000522, acc.: 100.00%] [G loss: 0.026380]\n",
      "94 [D loss: 0.000828, acc.: 100.00%] [G loss: 0.020302]\n",
      "95 [D loss: 0.000485, acc.: 100.00%] [G loss: 0.018529]\n",
      "96 [D loss: 0.001127, acc.: 100.00%] [G loss: 0.029371]\n",
      "97 [D loss: 0.001411, acc.: 100.00%] [G loss: 0.027474]\n",
      "98 [D loss: 0.000595, acc.: 100.00%] [G loss: 0.025318]\n",
      "99 [D loss: 0.000233, acc.: 100.00%] [G loss: 0.016364]\n",
      "100 [D loss: 0.001694, acc.: 100.00%] [G loss: 0.016841]\n",
      "Generating interpolations...\n",
      "101 [D loss: 0.000459, acc.: 100.00%] [G loss: 0.015248]\n",
      "102 [D loss: 0.000577, acc.: 100.00%] [G loss: 0.015159]\n",
      "103 [D loss: 0.000377, acc.: 100.00%] [G loss: 0.017375]\n",
      "104 [D loss: 0.000485, acc.: 100.00%] [G loss: 0.016943]\n",
      "105 [D loss: 0.000611, acc.: 100.00%] [G loss: 0.029927]\n",
      "106 [D loss: 0.000438, acc.: 100.00%] [G loss: 0.021912]\n",
      "107 [D loss: 0.000274, acc.: 100.00%] [G loss: 0.013360]\n",
      "108 [D loss: 0.000484, acc.: 100.00%] [G loss: 0.024459]\n",
      "109 [D loss: 0.000304, acc.: 100.00%] [G loss: 0.021629]\n",
      "110 [D loss: 0.000827, acc.: 100.00%] [G loss: 0.024490]\n",
      "111 [D loss: 0.001581, acc.: 100.00%] [G loss: 0.020908]\n",
      "112 [D loss: 0.000884, acc.: 100.00%] [G loss: 0.017960]\n",
      "113 [D loss: 0.000357, acc.: 100.00%] [G loss: 0.013460]\n",
      "114 [D loss: 0.000339, acc.: 100.00%] [G loss: 0.010848]\n",
      "115 [D loss: 0.000317, acc.: 100.00%] [G loss: 0.011741]\n",
      "116 [D loss: 0.000454, acc.: 100.00%] [G loss: 0.017601]\n",
      "117 [D loss: 0.002377, acc.: 100.00%] [G loss: 0.017998]\n",
      "118 [D loss: 0.000462, acc.: 100.00%] [G loss: 0.019248]\n",
      "119 [D loss: 0.000905, acc.: 100.00%] [G loss: 0.025499]\n",
      "120 [D loss: 0.000874, acc.: 100.00%] [G loss: 0.020670]\n",
      "121 [D loss: 0.000352, acc.: 100.00%] [G loss: 0.021096]\n",
      "122 [D loss: 0.000197, acc.: 100.00%] [G loss: 0.010443]\n",
      "123 [D loss: 0.000341, acc.: 100.00%] [G loss: 0.013620]\n",
      "124 [D loss: 0.000326, acc.: 100.00%] [G loss: 0.016145]\n",
      "125 [D loss: 0.000415, acc.: 100.00%] [G loss: 0.015054]\n",
      "126 [D loss: 0.000467, acc.: 100.00%] [G loss: 0.021260]\n",
      "127 [D loss: 0.001016, acc.: 100.00%] [G loss: 0.022161]\n",
      "128 [D loss: 0.000290, acc.: 100.00%] [G loss: 0.013427]\n",
      "129 [D loss: 0.000316, acc.: 100.00%] [G loss: 0.019576]\n",
      "130 [D loss: 0.000342, acc.: 100.00%] [G loss: 0.016938]\n",
      "131 [D loss: 0.000495, acc.: 100.00%] [G loss: 0.012785]\n",
      "132 [D loss: 0.000460, acc.: 100.00%] [G loss: 0.025612]\n",
      "133 [D loss: 0.000946, acc.: 100.00%] [G loss: 0.012190]\n",
      "134 [D loss: 0.000452, acc.: 100.00%] [G loss: 0.015050]\n",
      "135 [D loss: 0.000579, acc.: 100.00%] [G loss: 0.012137]\n",
      "136 [D loss: 0.000397, acc.: 100.00%] [G loss: 0.013252]\n",
      "137 [D loss: 0.000311, acc.: 100.00%] [G loss: 0.016466]\n",
      "138 [D loss: 0.000150, acc.: 100.00%] [G loss: 0.013832]\n",
      "139 [D loss: 0.000419, acc.: 100.00%] [G loss: 0.012687]\n",
      "140 [D loss: 0.000158, acc.: 100.00%] [G loss: 0.014023]\n",
      "141 [D loss: 0.000158, acc.: 100.00%] [G loss: 0.012252]\n",
      "142 [D loss: 0.000266, acc.: 100.00%] [G loss: 0.014420]\n",
      "143 [D loss: 0.000559, acc.: 100.00%] [G loss: 0.011395]\n",
      "144 [D loss: 0.000250, acc.: 100.00%] [G loss: 0.013182]\n",
      "145 [D loss: 0.000250, acc.: 100.00%] [G loss: 0.011807]\n",
      "146 [D loss: 0.000406, acc.: 100.00%] [G loss: 0.017780]\n",
      "147 [D loss: 0.000231, acc.: 100.00%] [G loss: 0.014786]\n",
      "148 [D loss: 0.000250, acc.: 100.00%] [G loss: 0.015421]\n",
      "149 [D loss: 0.000179, acc.: 100.00%] [G loss: 0.011127]\n",
      "150 [D loss: 0.000154, acc.: 100.00%] [G loss: 0.015401]\n",
      "Generating interpolations...\n",
      "151 [D loss: 0.000438, acc.: 100.00%] [G loss: 0.017411]\n",
      "152 [D loss: 0.000268, acc.: 100.00%] [G loss: 0.011885]\n",
      "153 [D loss: 0.000184, acc.: 100.00%] [G loss: 0.013148]\n",
      "154 [D loss: 0.000112, acc.: 100.00%] [G loss: 0.011416]\n",
      "155 [D loss: 0.000142, acc.: 100.00%] [G loss: 0.012191]\n",
      "156 [D loss: 0.000121, acc.: 100.00%] [G loss: 0.012298]\n",
      "157 [D loss: 0.000182, acc.: 100.00%] [G loss: 0.014968]\n",
      "158 [D loss: 0.000267, acc.: 100.00%] [G loss: 0.012973]\n",
      "159 [D loss: 0.000508, acc.: 100.00%] [G loss: 0.013680]\n",
      "160 [D loss: 0.000857, acc.: 100.00%] [G loss: 0.012639]\n",
      "161 [D loss: 0.000161, acc.: 100.00%] [G loss: 0.010281]\n",
      "162 [D loss: 0.000307, acc.: 100.00%] [G loss: 0.013153]\n",
      "163 [D loss: 0.000503, acc.: 100.00%] [G loss: 0.011007]\n",
      "164 [D loss: 0.000178, acc.: 100.00%] [G loss: 0.010899]\n",
      "165 [D loss: 0.000332, acc.: 100.00%] [G loss: 0.010885]\n",
      "166 [D loss: 0.000174, acc.: 100.00%] [G loss: 0.009814]\n",
      "167 [D loss: 0.000267, acc.: 100.00%] [G loss: 0.010307]\n",
      "168 [D loss: 0.000245, acc.: 100.00%] [G loss: 0.012498]\n",
      "169 [D loss: 0.000741, acc.: 100.00%] [G loss: 0.013905]\n",
      "170 [D loss: 0.000167, acc.: 100.00%] [G loss: 0.012719]\n",
      "171 [D loss: 0.000225, acc.: 100.00%] [G loss: 0.007757]\n",
      "172 [D loss: 0.000128, acc.: 100.00%] [G loss: 0.010828]\n",
      "173 [D loss: 0.000224, acc.: 100.00%] [G loss: 0.017799]\n",
      "174 [D loss: 0.000281, acc.: 100.00%] [G loss: 0.011858]\n",
      "175 [D loss: 0.000304, acc.: 100.00%] [G loss: 0.013627]\n",
      "176 [D loss: 0.000126, acc.: 100.00%] [G loss: 0.010730]\n",
      "177 [D loss: 0.000129, acc.: 100.00%] [G loss: 0.008828]\n",
      "178 [D loss: 0.000067, acc.: 100.00%] [G loss: 0.009492]\n",
      "179 [D loss: 0.000242, acc.: 100.00%] [G loss: 0.014218]\n",
      "180 [D loss: 0.000156, acc.: 100.00%] [G loss: 0.009616]\n",
      "181 [D loss: 0.000203, acc.: 100.00%] [G loss: 0.014088]\n",
      "182 [D loss: 0.000145, acc.: 100.00%] [G loss: 0.011010]\n",
      "183 [D loss: 0.000200, acc.: 100.00%] [G loss: 0.014831]\n",
      "184 [D loss: 0.000115, acc.: 100.00%] [G loss: 0.013512]\n",
      "185 [D loss: 0.000226, acc.: 100.00%] [G loss: 0.008522]\n",
      "186 [D loss: 0.000086, acc.: 100.00%] [G loss: 0.011146]\n",
      "187 [D loss: 0.000186, acc.: 100.00%] [G loss: 0.008867]\n",
      "188 [D loss: 0.000104, acc.: 100.00%] [G loss: 0.008137]\n",
      "189 [D loss: 0.000113, acc.: 100.00%] [G loss: 0.012131]\n",
      "190 [D loss: 0.000218, acc.: 100.00%] [G loss: 0.008888]\n",
      "191 [D loss: 0.001452, acc.: 100.00%] [G loss: 0.008631]\n",
      "192 [D loss: 0.000328, acc.: 100.00%] [G loss: 0.008470]\n",
      "193 [D loss: 0.000103, acc.: 100.00%] [G loss: 0.007219]\n",
      "194 [D loss: 0.000716, acc.: 100.00%] [G loss: 0.008863]\n",
      "195 [D loss: 0.000180, acc.: 100.00%] [G loss: 0.006348]\n",
      "196 [D loss: 0.000168, acc.: 100.00%] [G loss: 0.006133]\n",
      "197 [D loss: 0.000241, acc.: 100.00%] [G loss: 0.004700]\n",
      "198 [D loss: 0.000206, acc.: 100.00%] [G loss: 0.006999]\n",
      "199 [D loss: 0.000267, acc.: 100.00%] [G loss: 0.007460]\n",
      "200 [D loss: 0.000196, acc.: 100.00%] [G loss: 0.008666]\n",
      "Generating interpolations...\n",
      "201 [D loss: 0.000252, acc.: 100.00%] [G loss: 0.009093]\n",
      "202 [D loss: 0.000121, acc.: 100.00%] [G loss: 0.004854]\n",
      "203 [D loss: 0.000073, acc.: 100.00%] [G loss: 0.006225]\n",
      "204 [D loss: 0.000254, acc.: 100.00%] [G loss: 0.007974]\n",
      "205 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.003801]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206 [D loss: 0.000072, acc.: 100.00%] [G loss: 0.004164]\n",
      "207 [D loss: 0.000165, acc.: 100.00%] [G loss: 0.005603]\n",
      "208 [D loss: 0.000184, acc.: 100.00%] [G loss: 0.009560]\n",
      "209 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.006056]\n",
      "210 [D loss: 0.000246, acc.: 100.00%] [G loss: 0.010732]\n",
      "211 [D loss: 0.000176, acc.: 100.00%] [G loss: 0.009767]\n",
      "212 [D loss: 0.000184, acc.: 100.00%] [G loss: 0.017199]\n",
      "213 [D loss: 0.000291, acc.: 100.00%] [G loss: 0.007195]\n",
      "214 [D loss: 0.000218, acc.: 100.00%] [G loss: 0.013500]\n",
      "215 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.009329]\n",
      "216 [D loss: 0.000265, acc.: 100.00%] [G loss: 0.008313]\n",
      "217 [D loss: 0.000116, acc.: 100.00%] [G loss: 0.009129]\n",
      "218 [D loss: 0.000077, acc.: 100.00%] [G loss: 0.005409]\n",
      "219 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.005079]\n",
      "220 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.006445]\n",
      "221 [D loss: 0.000096, acc.: 100.00%] [G loss: 0.004774]\n",
      "222 [D loss: 0.000084, acc.: 100.00%] [G loss: 0.004473]\n",
      "223 [D loss: 0.000091, acc.: 100.00%] [G loss: 0.006803]\n",
      "224 [D loss: 0.000129, acc.: 100.00%] [G loss: 0.006855]\n",
      "225 [D loss: 0.000045, acc.: 100.00%] [G loss: 0.007000]\n",
      "226 [D loss: 0.000054, acc.: 100.00%] [G loss: 0.004525]\n",
      "227 [D loss: 0.000060, acc.: 100.00%] [G loss: 0.004076]\n",
      "228 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.003539]\n",
      "229 [D loss: 0.000059, acc.: 100.00%] [G loss: 0.004700]\n",
      "230 [D loss: 0.000122, acc.: 100.00%] [G loss: 0.004297]\n",
      "231 [D loss: 0.000140, acc.: 100.00%] [G loss: 0.006187]\n",
      "232 [D loss: 0.000069, acc.: 100.00%] [G loss: 0.007306]\n",
      "233 [D loss: 0.000073, acc.: 100.00%] [G loss: 0.005601]\n",
      "234 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.006781]\n",
      "235 [D loss: 0.000075, acc.: 100.00%] [G loss: 0.007262]\n",
      "236 [D loss: 0.000064, acc.: 100.00%] [G loss: 0.005334]\n",
      "237 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.005481]\n",
      "238 [D loss: 0.000249, acc.: 100.00%] [G loss: 0.007560]\n",
      "239 [D loss: 0.000085, acc.: 100.00%] [G loss: 0.006811]\n",
      "240 [D loss: 0.000076, acc.: 100.00%] [G loss: 0.007302]\n",
      "241 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.004473]\n",
      "242 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.003902]\n",
      "243 [D loss: 0.000092, acc.: 100.00%] [G loss: 0.009047]\n",
      "244 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.007908]\n",
      "245 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.005042]\n",
      "246 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.004010]\n",
      "247 [D loss: 0.000064, acc.: 100.00%] [G loss: 0.006230]\n",
      "248 [D loss: 0.000309, acc.: 100.00%] [G loss: 0.005509]\n",
      "249 [D loss: 0.000379, acc.: 100.00%] [G loss: 0.007501]\n",
      "250 [D loss: 0.000085, acc.: 100.00%] [G loss: 0.005201]\n",
      "Generating interpolations...\n",
      "251 [D loss: 0.000029, acc.: 100.00%] [G loss: 0.006885]\n",
      "252 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.005936]\n",
      "253 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.009509]\n",
      "254 [D loss: 0.000490, acc.: 100.00%] [G loss: 0.009291]\n",
      "255 [D loss: 0.000085, acc.: 100.00%] [G loss: 0.009382]\n",
      "256 [D loss: 0.000086, acc.: 100.00%] [G loss: 0.007247]\n",
      "257 [D loss: 0.000114, acc.: 100.00%] [G loss: 0.004749]\n",
      "258 [D loss: 0.000089, acc.: 100.00%] [G loss: 0.006627]\n",
      "259 [D loss: 0.000046, acc.: 100.00%] [G loss: 0.004800]\n",
      "260 [D loss: 0.000067, acc.: 100.00%] [G loss: 0.005278]\n",
      "261 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.003724]\n",
      "262 [D loss: 0.000198, acc.: 100.00%] [G loss: 0.005247]\n",
      "263 [D loss: 0.000045, acc.: 100.00%] [G loss: 0.005433]\n",
      "264 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.003414]\n",
      "265 [D loss: 0.000057, acc.: 100.00%] [G loss: 0.005291]\n",
      "266 [D loss: 0.000048, acc.: 100.00%] [G loss: 0.005271]\n",
      "267 [D loss: 0.000186, acc.: 100.00%] [G loss: 0.007433]\n",
      "268 [D loss: 0.000088, acc.: 100.00%] [G loss: 0.011544]\n",
      "269 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.009626]\n",
      "270 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.011100]\n",
      "271 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.007638]\n",
      "272 [D loss: 0.000055, acc.: 100.00%] [G loss: 0.006611]\n",
      "273 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.007333]\n",
      "274 [D loss: 0.000109, acc.: 100.00%] [G loss: 0.005527]\n",
      "275 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.004829]\n",
      "276 [D loss: 0.000043, acc.: 100.00%] [G loss: 0.005077]\n",
      "277 [D loss: 0.000100, acc.: 100.00%] [G loss: 0.005268]\n",
      "278 [D loss: 0.000118, acc.: 100.00%] [G loss: 0.010104]\n",
      "279 [D loss: 0.000078, acc.: 100.00%] [G loss: 0.005906]\n",
      "280 [D loss: 0.000043, acc.: 100.00%] [G loss: 0.004165]\n",
      "281 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.003294]\n",
      "282 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.003682]\n",
      "283 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.003586]\n",
      "284 [D loss: 0.000046, acc.: 100.00%] [G loss: 0.004349]\n",
      "285 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.005804]\n",
      "286 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.003630]\n",
      "287 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.003578]\n",
      "288 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.003555]\n",
      "289 [D loss: 0.000121, acc.: 100.00%] [G loss: 0.003492]\n",
      "290 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.002875]\n",
      "291 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.003957]\n",
      "292 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.003523]\n",
      "293 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.004489]\n",
      "294 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.005475]\n",
      "295 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.006184]\n",
      "296 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.012076]\n",
      "297 [D loss: 0.000063, acc.: 100.00%] [G loss: 0.003915]\n",
      "298 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.005130]\n",
      "299 [D loss: 0.000045, acc.: 100.00%] [G loss: 0.003812]\n",
      "300 [D loss: 0.000043, acc.: 100.00%] [G loss: 0.002352]\n",
      "Generating interpolations...\n",
      "301 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.002868]\n",
      "302 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.002515]\n",
      "303 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.002595]\n",
      "304 [D loss: 0.000047, acc.: 100.00%] [G loss: 0.004369]\n",
      "305 [D loss: 0.000047, acc.: 100.00%] [G loss: 0.009798]\n",
      "306 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.005520]\n",
      "307 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.009601]\n",
      "308 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.004612]\n",
      "309 [D loss: 0.000110, acc.: 100.00%] [G loss: 0.007294]\n",
      "310 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.005296]\n",
      "311 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.004584]\n",
      "312 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.005553]\n",
      "313 [D loss: 0.000096, acc.: 100.00%] [G loss: 0.004954]\n",
      "314 [D loss: 0.000063, acc.: 100.00%] [G loss: 0.006266]\n",
      "315 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.003794]\n",
      "316 [D loss: 0.000048, acc.: 100.00%] [G loss: 0.004593]\n",
      "317 [D loss: 0.000080, acc.: 100.00%] [G loss: 0.004802]\n",
      "318 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.004985]\n",
      "319 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.005213]\n",
      "320 [D loss: 0.000086, acc.: 100.00%] [G loss: 0.004622]\n",
      "321 [D loss: 0.000146, acc.: 100.00%] [G loss: 0.004373]\n",
      "322 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.003785]\n",
      "323 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.003928]\n",
      "324 [D loss: 0.000068, acc.: 100.00%] [G loss: 0.005779]\n",
      "325 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.003395]\n",
      "326 [D loss: 0.000063, acc.: 100.00%] [G loss: 0.005984]\n",
      "327 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.002982]\n",
      "328 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.005987]\n",
      "329 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.003027]\n",
      "330 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.003516]\n",
      "331 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.005090]\n",
      "332 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.003954]\n",
      "333 [D loss: 0.000059, acc.: 100.00%] [G loss: 0.006689]\n",
      "334 [D loss: 0.000081, acc.: 100.00%] [G loss: 0.003922]\n",
      "335 [D loss: 0.000099, acc.: 100.00%] [G loss: 0.004382]\n",
      "336 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002473]\n",
      "337 [D loss: 0.000082, acc.: 100.00%] [G loss: 0.005373]\n",
      "338 [D loss: 0.000102, acc.: 100.00%] [G loss: 0.004154]\n",
      "339 [D loss: 0.000100, acc.: 100.00%] [G loss: 0.002913]\n",
      "340 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.003478]\n",
      "341 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.003419]\n",
      "342 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.003165]\n",
      "343 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.002911]\n",
      "344 [D loss: 0.000079, acc.: 100.00%] [G loss: 0.003694]\n",
      "345 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.003169]\n",
      "346 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.002290]\n",
      "347 [D loss: 0.000045, acc.: 100.00%] [G loss: 0.002981]\n",
      "348 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.004365]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.003792]\n",
      "350 [D loss: 0.000058, acc.: 100.00%] [G loss: 0.003329]\n",
      "Generating interpolations...\n",
      "351 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.005327]\n",
      "352 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.003197]\n",
      "353 [D loss: 0.000060, acc.: 100.00%] [G loss: 0.004578]\n",
      "354 [D loss: 0.000052, acc.: 100.00%] [G loss: 0.003794]\n",
      "355 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.004444]\n",
      "356 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002203]\n",
      "357 [D loss: 0.000067, acc.: 100.00%] [G loss: 0.004413]\n",
      "358 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.003153]\n",
      "359 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.003172]\n",
      "360 [D loss: 0.000055, acc.: 100.00%] [G loss: 0.004434]\n",
      "361 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.002874]\n",
      "362 [D loss: 0.000070, acc.: 100.00%] [G loss: 0.004077]\n",
      "363 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.002623]\n",
      "364 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.002196]\n",
      "365 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.001662]\n",
      "366 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.002993]\n",
      "367 [D loss: 0.000170, acc.: 100.00%] [G loss: 0.003878]\n",
      "368 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002294]\n",
      "369 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.002427]\n",
      "370 [D loss: 0.000044, acc.: 100.00%] [G loss: 0.002833]\n",
      "371 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.001645]\n",
      "372 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.003125]\n",
      "373 [D loss: 0.000056, acc.: 100.00%] [G loss: 0.003117]\n",
      "374 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.002969]\n",
      "375 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.004131]\n",
      "376 [D loss: 0.000060, acc.: 100.00%] [G loss: 0.004219]\n",
      "377 [D loss: 0.000570, acc.: 100.00%] [G loss: 0.003559]\n",
      "378 [D loss: 0.000050, acc.: 100.00%] [G loss: 0.004124]\n",
      "379 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.004225]\n",
      "380 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.003069]\n",
      "381 [D loss: 0.000082, acc.: 100.00%] [G loss: 0.003280]\n",
      "382 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001896]\n",
      "383 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.002752]\n",
      "384 [D loss: 0.000224, acc.: 100.00%] [G loss: 0.003571]\n",
      "385 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.004289]\n",
      "386 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.002539]\n",
      "387 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.001954]\n",
      "388 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.002210]\n",
      "389 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.001796]\n",
      "390 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.002001]\n",
      "391 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002122]\n",
      "392 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001461]\n",
      "393 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.002100]\n",
      "394 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001679]\n",
      "395 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001010]\n",
      "396 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.002535]\n",
      "397 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.001822]\n",
      "398 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.002130]\n",
      "399 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.002523]\n",
      "400 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.002430]\n",
      "Generating interpolations...\n",
      "401 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001883]\n",
      "402 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.002661]\n",
      "403 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001957]\n",
      "404 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.002452]\n",
      "405 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001548]\n",
      "406 [D loss: 0.000093, acc.: 100.00%] [G loss: 0.003694]\n",
      "407 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001767]\n",
      "408 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.002365]\n",
      "409 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.001486]\n",
      "410 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.003710]\n",
      "411 [D loss: 0.000101, acc.: 100.00%] [G loss: 0.005134]\n",
      "412 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.006962]\n",
      "413 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.002393]\n",
      "414 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.002721]\n",
      "415 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.002111]\n",
      "416 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002286]\n",
      "417 [D loss: 0.000030, acc.: 100.00%] [G loss: 0.003269]\n",
      "418 [D loss: 0.000051, acc.: 100.00%] [G loss: 0.002533]\n",
      "419 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.001728]\n",
      "420 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.002035]\n",
      "421 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.002754]\n",
      "422 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.003615]\n",
      "423 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001903]\n",
      "424 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.002190]\n",
      "425 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001832]\n",
      "426 [D loss: 0.000071, acc.: 100.00%] [G loss: 0.003174]\n",
      "427 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.002666]\n",
      "428 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.003025]\n",
      "429 [D loss: 0.000073, acc.: 100.00%] [G loss: 0.003009]\n",
      "430 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.002263]\n",
      "431 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.002848]\n",
      "432 [D loss: 0.000110, acc.: 100.00%] [G loss: 0.002850]\n",
      "433 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.002142]\n",
      "434 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.003754]\n",
      "435 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.002868]\n",
      "436 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.002215]\n",
      "437 [D loss: 0.000037, acc.: 100.00%] [G loss: 0.002254]\n",
      "438 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002247]\n",
      "439 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.003065]\n",
      "440 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002295]\n",
      "441 [D loss: 0.000055, acc.: 100.00%] [G loss: 0.003461]\n",
      "442 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002931]\n",
      "443 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.002621]\n",
      "444 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.002990]\n",
      "445 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002090]\n",
      "446 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002074]\n",
      "447 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002744]\n",
      "448 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.002616]\n",
      "449 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.002079]\n",
      "450 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002335]\n",
      "Generating interpolations...\n",
      "451 [D loss: 0.000027, acc.: 100.00%] [G loss: 0.001684]\n",
      "452 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001854]\n",
      "453 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001526]\n",
      "454 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.002194]\n",
      "455 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.002192]\n",
      "456 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.002693]\n",
      "457 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.003566]\n",
      "458 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002540]\n",
      "459 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002645]\n",
      "460 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.002450]\n",
      "461 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.002615]\n",
      "462 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.003340]\n",
      "463 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.002198]\n",
      "464 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.003445]\n",
      "465 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.003180]\n",
      "466 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.004334]\n",
      "467 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001721]\n",
      "468 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001903]\n",
      "469 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002394]\n",
      "470 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001583]\n",
      "471 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001670]\n",
      "472 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001945]\n",
      "473 [D loss: 0.000069, acc.: 100.00%] [G loss: 0.003551]\n",
      "474 [D loss: 0.000040, acc.: 100.00%] [G loss: 0.003699]\n",
      "475 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.003584]\n",
      "476 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001681]\n",
      "477 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.002153]\n",
      "478 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001330]\n",
      "479 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001907]\n",
      "480 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001464]\n",
      "481 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.002190]\n",
      "482 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.002182]\n",
      "483 [D loss: 0.000039, acc.: 100.00%] [G loss: 0.002292]\n",
      "484 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001486]\n",
      "485 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.002084]\n",
      "486 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001859]\n",
      "487 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.002459]\n",
      "488 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001503]\n",
      "489 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001711]\n",
      "490 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001176]\n",
      "491 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001646]\n",
      "493 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001296]\n",
      "494 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001435]\n",
      "495 [D loss: 0.000033, acc.: 100.00%] [G loss: 0.001503]\n",
      "496 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001346]\n",
      "497 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001340]\n",
      "498 [D loss: 0.000053, acc.: 100.00%] [G loss: 0.002327]\n",
      "499 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002656]\n",
      "500 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.002898]\n",
      "Generating interpolations...\n",
      "501 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.002105]\n",
      "502 [D loss: 0.000109, acc.: 100.00%] [G loss: 0.002416]\n",
      "503 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002350]\n",
      "504 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.002254]\n",
      "505 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001997]\n",
      "506 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002343]\n",
      "507 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.002249]\n",
      "508 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.002338]\n",
      "509 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.002586]\n",
      "510 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001866]\n",
      "511 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001356]\n",
      "512 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001708]\n",
      "513 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001462]\n",
      "514 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000890]\n",
      "515 [D loss: 0.000026, acc.: 100.00%] [G loss: 0.002115]\n",
      "516 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.003057]\n",
      "517 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001420]\n",
      "518 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001179]\n",
      "519 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.002746]\n",
      "520 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002430]\n",
      "521 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001557]\n",
      "522 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001851]\n",
      "523 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002225]\n",
      "524 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.002503]\n",
      "525 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001603]\n",
      "526 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001592]\n",
      "527 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001452]\n",
      "528 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001438]\n",
      "529 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.001855]\n",
      "530 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001425]\n",
      "531 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.001253]\n",
      "532 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001641]\n",
      "533 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.003846]\n",
      "534 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.002581]\n",
      "535 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001135]\n",
      "536 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.002214]\n",
      "537 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001491]\n",
      "538 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.001758]\n",
      "539 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001918]\n",
      "540 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001773]\n",
      "541 [D loss: 0.000144, acc.: 100.00%] [G loss: 0.003414]\n",
      "542 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002805]\n",
      "543 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001932]\n",
      "544 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001997]\n",
      "545 [D loss: 0.000034, acc.: 100.00%] [G loss: 0.003574]\n",
      "546 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001730]\n",
      "547 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001620]\n",
      "548 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001253]\n",
      "549 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001199]\n",
      "550 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001169]\n",
      "Generating interpolations...\n",
      "551 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001753]\n",
      "552 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.002465]\n",
      "553 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002113]\n",
      "554 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001283]\n",
      "555 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001603]\n",
      "556 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001269]\n",
      "557 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001568]\n",
      "558 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001713]\n",
      "559 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001341]\n",
      "560 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.002095]\n",
      "561 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.002470]\n",
      "562 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001368]\n",
      "563 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002581]\n",
      "564 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001265]\n",
      "565 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.002041]\n",
      "566 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001647]\n",
      "567 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001776]\n",
      "568 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001093]\n",
      "569 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001221]\n",
      "570 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001045]\n",
      "571 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000980]\n",
      "572 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001204]\n",
      "573 [D loss: 0.000062, acc.: 100.00%] [G loss: 0.002116]\n",
      "574 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001402]\n",
      "575 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.002279]\n",
      "576 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001809]\n",
      "577 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.001766]\n",
      "578 [D loss: 0.000060, acc.: 100.00%] [G loss: 0.002110]\n",
      "579 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001318]\n",
      "580 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001453]\n",
      "581 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001657]\n",
      "582 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.002449]\n",
      "583 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001486]\n",
      "584 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001973]\n",
      "585 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001122]\n",
      "586 [D loss: 0.000065, acc.: 100.00%] [G loss: 0.001870]\n",
      "587 [D loss: 0.000043, acc.: 100.00%] [G loss: 0.002619]\n",
      "588 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.002656]\n",
      "589 [D loss: 0.000086, acc.: 100.00%] [G loss: 0.002263]\n",
      "590 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001851]\n",
      "591 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001609]\n",
      "592 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001667]\n",
      "593 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001937]\n",
      "594 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001263]\n",
      "595 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001474]\n",
      "596 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000986]\n",
      "597 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001385]\n",
      "598 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001261]\n",
      "599 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000917]\n",
      "600 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.000981]\n",
      "Generating interpolations...\n",
      "601 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.002136]\n",
      "602 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001763]\n",
      "603 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001654]\n",
      "604 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001658]\n",
      "605 [D loss: 0.000038, acc.: 100.00%] [G loss: 0.002102]\n",
      "606 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001840]\n",
      "607 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.002984]\n",
      "608 [D loss: 0.000046, acc.: 100.00%] [G loss: 0.003022]\n",
      "609 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001993]\n",
      "610 [D loss: 0.000054, acc.: 100.00%] [G loss: 0.001986]\n",
      "611 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001683]\n",
      "612 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001359]\n",
      "613 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000957]\n",
      "614 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001286]\n",
      "615 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.001143]\n",
      "616 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000966]\n",
      "617 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.002255]\n",
      "618 [D loss: 0.000036, acc.: 100.00%] [G loss: 0.002498]\n",
      "619 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001382]\n",
      "620 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001263]\n",
      "621 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000958]\n",
      "622 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001173]\n",
      "623 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000726]\n",
      "624 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000743]\n",
      "625 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001165]\n",
      "626 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001191]\n",
      "627 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001055]\n",
      "628 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.001487]\n",
      "629 [D loss: 0.000042, acc.: 100.00%] [G loss: 0.001667]\n",
      "630 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001190]\n",
      "631 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001265]\n",
      "632 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001430]\n",
      "633 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001349]\n",
      "634 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000835]\n",
      "636 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000824]\n",
      "637 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001136]\n",
      "638 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001092]\n",
      "639 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001649]\n",
      "640 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001055]\n",
      "641 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000586]\n",
      "642 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001386]\n",
      "643 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000790]\n",
      "644 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.000803]\n",
      "645 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001082]\n",
      "646 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001016]\n",
      "647 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000924]\n",
      "648 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000713]\n",
      "649 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001920]\n",
      "650 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001347]\n",
      "Generating interpolations...\n",
      "651 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001382]\n",
      "652 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.002456]\n",
      "653 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000964]\n",
      "654 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000965]\n",
      "655 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.001899]\n",
      "656 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001038]\n",
      "657 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000900]\n",
      "658 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000725]\n",
      "659 [D loss: 0.000031, acc.: 100.00%] [G loss: 0.001574]\n",
      "660 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001105]\n",
      "661 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001871]\n",
      "662 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001343]\n",
      "663 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.001621]\n",
      "664 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.001440]\n",
      "665 [D loss: 0.000079, acc.: 100.00%] [G loss: 0.001998]\n",
      "666 [D loss: 0.000025, acc.: 100.00%] [G loss: 0.002024]\n",
      "667 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001662]\n",
      "668 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001571]\n",
      "669 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001451]\n",
      "670 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001296]\n",
      "671 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001084]\n",
      "672 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001402]\n",
      "673 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001419]\n",
      "674 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000687]\n",
      "675 [D loss: 0.000041, acc.: 100.00%] [G loss: 0.001307]\n",
      "676 [D loss: 0.000049, acc.: 100.00%] [G loss: 0.001663]\n",
      "677 [D loss: 0.000066, acc.: 100.00%] [G loss: 0.001848]\n",
      "678 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.002274]\n",
      "679 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001160]\n",
      "680 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000813]\n",
      "681 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001313]\n",
      "682 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001231]\n",
      "683 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.001450]\n",
      "684 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001103]\n",
      "685 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001294]\n",
      "686 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001402]\n",
      "687 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001016]\n",
      "688 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001260]\n",
      "689 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.000975]\n",
      "690 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001272]\n",
      "691 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001148]\n",
      "692 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000854]\n",
      "693 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000957]\n",
      "694 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000547]\n",
      "695 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000964]\n",
      "696 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000765]\n",
      "697 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001258]\n",
      "698 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001101]\n",
      "699 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000920]\n",
      "700 [D loss: 0.000059, acc.: 100.00%] [G loss: 0.001296]\n",
      "Generating interpolations...\n",
      "701 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001721]\n",
      "702 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001230]\n",
      "703 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001970]\n",
      "704 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.001745]\n",
      "705 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.002532]\n",
      "706 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001110]\n",
      "707 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000912]\n",
      "708 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000884]\n",
      "709 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000823]\n",
      "710 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001006]\n",
      "711 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000716]\n",
      "712 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000905]\n",
      "713 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000985]\n",
      "714 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001053]\n",
      "715 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001304]\n",
      "716 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001118]\n",
      "717 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001354]\n",
      "718 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.002205]\n",
      "719 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001364]\n",
      "720 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001111]\n",
      "721 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001281]\n",
      "722 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001201]\n",
      "723 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000642]\n",
      "724 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001704]\n",
      "725 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.002347]\n",
      "726 [D loss: 0.000032, acc.: 100.00%] [G loss: 0.001522]\n",
      "727 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001232]\n",
      "728 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000786]\n",
      "729 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001104]\n",
      "730 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001926]\n",
      "731 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000708]\n",
      "732 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000803]\n",
      "733 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000893]\n",
      "734 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000646]\n",
      "735 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001487]\n",
      "736 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000911]\n",
      "737 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000522]\n",
      "738 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000655]\n",
      "739 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.003057]\n",
      "740 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000682]\n",
      "741 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000910]\n",
      "742 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000580]\n",
      "743 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000756]\n",
      "744 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001645]\n",
      "745 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000748]\n",
      "746 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001062]\n",
      "747 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000693]\n",
      "748 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001291]\n",
      "749 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000933]\n",
      "750 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000924]\n",
      "Generating interpolations...\n",
      "751 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001010]\n",
      "752 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000827]\n",
      "753 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000525]\n",
      "754 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000607]\n",
      "755 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000833]\n",
      "756 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001196]\n",
      "757 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001080]\n",
      "758 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001374]\n",
      "759 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001926]\n",
      "760 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001572]\n",
      "761 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.002431]\n",
      "762 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.001867]\n",
      "763 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001216]\n",
      "764 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001250]\n",
      "765 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000995]\n",
      "766 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.001844]\n",
      "767 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000818]\n",
      "768 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001092]\n",
      "769 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000766]\n",
      "770 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000860]\n",
      "771 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001265]\n",
      "772 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001193]\n",
      "773 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001076]\n",
      "774 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000710]\n",
      "775 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000619]\n",
      "776 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000886]\n",
      "777 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000775]\n",
      "779 [D loss: 0.000138, acc.: 100.00%] [G loss: 0.001246]\n",
      "780 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001157]\n",
      "781 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000986]\n",
      "782 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000625]\n",
      "783 [D loss: 0.000092, acc.: 100.00%] [G loss: 0.000920]\n",
      "784 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001976]\n",
      "785 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.001909]\n",
      "786 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001447]\n",
      "787 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000519]\n",
      "788 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000562]\n",
      "789 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000606]\n",
      "790 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000569]\n",
      "791 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.001183]\n",
      "792 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000593]\n",
      "793 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000506]\n",
      "794 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000679]\n",
      "795 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000873]\n",
      "796 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000854]\n",
      "797 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000798]\n",
      "798 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000560]\n",
      "799 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000751]\n",
      "800 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000837]\n",
      "Generating interpolations...\n",
      "801 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001204]\n",
      "802 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000971]\n",
      "803 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000559]\n",
      "804 [D loss: 0.000028, acc.: 100.00%] [G loss: 0.000977]\n",
      "805 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000844]\n",
      "806 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000945]\n",
      "807 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000656]\n",
      "808 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000616]\n",
      "809 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.001189]\n",
      "810 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000657]\n",
      "811 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001137]\n",
      "812 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000847]\n",
      "813 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000799]\n",
      "814 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001021]\n",
      "815 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001109]\n",
      "816 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000713]\n",
      "817 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000926]\n",
      "818 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001018]\n",
      "819 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000751]\n",
      "820 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000652]\n",
      "821 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000956]\n",
      "822 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000638]\n",
      "823 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000494]\n",
      "824 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000742]\n",
      "825 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000819]\n",
      "826 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001066]\n",
      "827 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000716]\n",
      "828 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.000863]\n",
      "829 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000737]\n",
      "830 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000904]\n",
      "831 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001292]\n",
      "832 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000811]\n",
      "833 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000646]\n",
      "834 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001059]\n",
      "835 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000807]\n",
      "836 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000921]\n",
      "837 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000549]\n",
      "838 [D loss: 0.000023, acc.: 100.00%] [G loss: 0.000796]\n",
      "839 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001149]\n",
      "840 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001675]\n",
      "841 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000771]\n",
      "842 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000907]\n",
      "843 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000861]\n",
      "844 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001168]\n",
      "845 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001340]\n",
      "846 [D loss: 0.000014, acc.: 100.00%] [G loss: 0.001257]\n",
      "847 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001826]\n",
      "848 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001293]\n",
      "849 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001055]\n",
      "850 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000897]\n",
      "Generating interpolations...\n",
      "851 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000815]\n",
      "852 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000851]\n",
      "853 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000923]\n",
      "854 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000805]\n",
      "855 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001164]\n",
      "856 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000786]\n",
      "857 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000771]\n",
      "858 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001078]\n",
      "859 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000980]\n",
      "860 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000828]\n",
      "861 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000812]\n",
      "862 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000596]\n",
      "863 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000843]\n",
      "864 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001151]\n",
      "865 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000719]\n",
      "866 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.001140]\n",
      "867 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000874]\n",
      "868 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000542]\n",
      "869 [D loss: 0.000010, acc.: 100.00%] [G loss: 0.000702]\n",
      "870 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000605]\n",
      "871 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001437]\n",
      "872 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001053]\n",
      "873 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000852]\n",
      "874 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000780]\n",
      "875 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000679]\n",
      "876 [D loss: 0.000019, acc.: 100.00%] [G loss: 0.001110]\n",
      "877 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.000928]\n",
      "878 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001203]\n",
      "879 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001484]\n",
      "880 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001197]\n",
      "881 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000987]\n",
      "882 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000735]\n",
      "883 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000735]\n",
      "884 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001229]\n",
      "885 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001077]\n",
      "886 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001007]\n",
      "887 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000929]\n",
      "888 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000344]\n",
      "889 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000650]\n",
      "890 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000737]\n",
      "891 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000799]\n",
      "892 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000728]\n",
      "893 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000929]\n",
      "894 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000995]\n",
      "895 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.001184]\n",
      "896 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000539]\n",
      "897 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000753]\n",
      "898 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000505]\n",
      "899 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000645]\n",
      "900 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000593]\n",
      "Generating interpolations...\n",
      "901 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000450]\n",
      "902 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000595]\n",
      "903 [D loss: 0.000068, acc.: 100.00%] [G loss: 0.001213]\n",
      "904 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001054]\n",
      "905 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000995]\n",
      "906 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001208]\n",
      "907 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.001219]\n",
      "908 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001539]\n",
      "909 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000856]\n",
      "910 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000797]\n",
      "911 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000919]\n",
      "912 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000666]\n",
      "913 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000377]\n",
      "914 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000447]\n",
      "915 [D loss: 0.000017, acc.: 100.00%] [G loss: 0.000599]\n",
      "916 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000702]\n",
      "917 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000493]\n",
      "918 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.001069]\n",
      "919 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000953]\n",
      "920 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000662]\n",
      "922 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000869]\n",
      "923 [D loss: 0.000018, acc.: 100.00%] [G loss: 0.000962]\n",
      "924 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000575]\n",
      "925 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000722]\n",
      "926 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000583]\n",
      "927 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000361]\n",
      "928 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000639]\n",
      "929 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000938]\n",
      "930 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000641]\n",
      "931 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000917]\n",
      "932 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.000629]\n",
      "933 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000595]\n",
      "934 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000746]\n",
      "935 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.001442]\n",
      "936 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000442]\n",
      "937 [D loss: 0.000016, acc.: 100.00%] [G loss: 0.000691]\n",
      "938 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000701]\n",
      "939 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000523]\n",
      "940 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000624]\n",
      "941 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000539]\n",
      "942 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000640]\n",
      "943 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001466]\n",
      "944 [D loss: 0.000020, acc.: 100.00%] [G loss: 0.001009]\n",
      "945 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000410]\n",
      "946 [D loss: 0.000008, acc.: 100.00%] [G loss: 0.000629]\n",
      "947 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000370]\n",
      "948 [D loss: 0.000022, acc.: 100.00%] [G loss: 0.001173]\n",
      "949 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000811]\n",
      "950 [D loss: 0.000012, acc.: 100.00%] [G loss: 0.001181]\n",
      "Generating interpolations...\n",
      "951 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000560]\n",
      "952 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000588]\n",
      "953 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000726]\n",
      "954 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.000822]\n",
      "955 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000867]\n",
      "956 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000648]\n",
      "957 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000490]\n",
      "958 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000443]\n",
      "959 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000516]\n",
      "960 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000548]\n",
      "961 [D loss: 0.000011, acc.: 100.00%] [G loss: 0.001046]\n",
      "962 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000548]\n",
      "963 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.001111]\n",
      "964 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000742]\n",
      "965 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001196]\n",
      "966 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000571]\n",
      "967 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000577]\n",
      "968 [D loss: 0.000080, acc.: 100.00%] [G loss: 0.001372]\n",
      "969 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000662]\n",
      "970 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000759]\n",
      "971 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000544]\n",
      "972 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000364]\n",
      "973 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000454]\n",
      "974 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000749]\n",
      "975 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000774]\n",
      "976 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000480]\n",
      "977 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000650]\n",
      "978 [D loss: 0.000007, acc.: 100.00%] [G loss: 0.000506]\n",
      "979 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000546]\n",
      "980 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000804]\n",
      "981 [D loss: 0.000015, acc.: 100.00%] [G loss: 0.000892]\n",
      "982 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001041]\n",
      "983 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000602]\n",
      "984 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.000571]\n",
      "985 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000496]\n",
      "986 [D loss: 0.000035, acc.: 100.00%] [G loss: 0.000995]\n",
      "987 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001102]\n",
      "988 [D loss: 0.000024, acc.: 100.00%] [G loss: 0.000987]\n",
      "989 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000848]\n",
      "990 [D loss: 0.000004, acc.: 100.00%] [G loss: 0.000561]\n",
      "991 [D loss: 0.000021, acc.: 100.00%] [G loss: 0.000774]\n",
      "992 [D loss: 0.000101, acc.: 100.00%] [G loss: 0.001139]\n",
      "993 [D loss: 0.000006, acc.: 100.00%] [G loss: 0.001045]\n",
      "994 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.001210]\n",
      "995 [D loss: 0.000005, acc.: 100.00%] [G loss: 0.000464]\n",
      "996 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000783]\n",
      "997 [D loss: 0.000003, acc.: 100.00%] [G loss: 0.000503]\n",
      "998 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000558]\n",
      "999 [D loss: 0.000013, acc.: 100.00%] [G loss: 0.000663]\n",
      "1000 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000420]\n",
      "Generating interpolations...\n",
      "1001 [D loss: 0.000002, acc.: 100.00%] [G loss: 0.000643]\n",
      "1002 [D loss: 0.000009, acc.: 100.00%] [G loss: 0.000753]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4360ada79f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mcheck_noise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_noise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m         \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-22-4360ada79f5a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, iterations, batch_size, save_interval, model_interval, check_noise, r, c)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m             \u001b[0mg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1346\u001b[0m                                                     class_weight)\n\u001b[1;32m   1347\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import better_exceptions\n",
    "################\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "np.random.RandomState(0)\n",
    "tf.compat.v1.set_random_seed(0)\n",
    "\n",
    "config = tf.compat.v1.ConfigProto(gpu_options=tf.compat.v1.GPUOptions(allow_growth=True))\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "# root_dir = \"/home/takusub/PycharmProjects/Samples/dcgan/kill_me_baby_datasets/\"\n",
    "#keras_dcgan.pyが保存されているディレクトリのフルパス\n",
    "root_dir = \"/Users/user/Desktop/m31_expt/m31_datasets/\"\n",
    "input_img_dir = \"all_resize\"\n",
    "save_dir = \"dcgan_v3_img/\"\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.class_names = os.listdir(root_dir)\n",
    "        \n",
    "        self.shape = (128, 128, 3)\n",
    "        self.z_dim = 100\n",
    "        \n",
    "        optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        self.generator = self.build_generator()\n",
    "        # self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "        \n",
    "        z = Input(shape=(self.z_dim,))\n",
    "        img = self.generator(z)\n",
    "        \n",
    "        self.discriminator.trainable = False\n",
    "        \n",
    "        valid = self.discriminator(img)\n",
    "        \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "    \n",
    "    def build_generator(self):\n",
    "        noise_shape = (self.z_dim,)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Dense(128 * 32 * 32, activation=\"relu\", input_shape=noise_shape))\n",
    "        model.add(Reshape((32, 32, 128)))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "        \n",
    "        return Model(noise, img)\n",
    "    \n",
    "    def build_discriminator(self):\n",
    "        img_shape = self.shape\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        model.summary()\n",
    "        \n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "        \n",
    "        return Model(img, validity)\n",
    "    \n",
    "    def build_combined(self):\n",
    "        self.discriminator.trainable = False\n",
    "        model = Sequential([self.generator, self.discriminator])\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def train(self, iterations, batch_size=128, save_interval=50, model_interval=10000, check_noise=None, r=5, c=5):\n",
    "        \n",
    "        X_train, labels = self.load_imgs()\n",
    "        \n",
    "        half_batch = int(batch_size / 2)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "        for iteration in range(iterations):\n",
    "            \n",
    "            # ------------------\n",
    "            # Training Discriminator\n",
    "            # -----------------\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            \n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (half_batch, self.z_dim))\n",
    "            \n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "            \n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            \n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "            \n",
    "            # -----------------\n",
    "            # Training Generator\n",
    "            # -----------------\n",
    "            \n",
    "            noise = np.random.uniform(-1, 1, (batch_size, self.z_dim))\n",
    "            \n",
    "            g_loss = self.combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "            \n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (iteration, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "            \n",
    "            if iteration % save_interval == 0:\n",
    "                self.save_imgs(iteration, check_noise, r, c)\n",
    "                start = np.expand_dims(check_noise[0], axis=0)\n",
    "                end = np.expand_dims(check_noise[1], axis=0)\n",
    "                resultImage = self.visualizeInterpolation(start=start, end=end)\n",
    "                # cv2.imwrite(\"images/latent/\" + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                cv2.imwrite(save_dir + \"latent_{}.png\".format(iteration), resultImage)\n",
    "                if iteration % model_interval == 0:\n",
    "                    # self.generator.save(\"ganmodels/dcgan-{}-iter.h5\".format(iteration))\n",
    "                    self.generator.save(\"mb_dcgan-{}-iter.h5\".format(iteration))\n",
    "\n",
    "    def save_imgs(self, iteration, check_noise, r, c):\n",
    "        noise = check_noise\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        # 0-1 rescale\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        \n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i, j].imshow(gen_imgs[cnt, :, :, :])\n",
    "                axs[i, j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(save_dir + '%d.png' % iteration)\n",
    "        # fig.savefig('images/gen_imgs/kill_me_%d.png' % iteration)\n",
    "        \n",
    "        plt.close()\n",
    "\n",
    "    def load_imgs(self):\n",
    "    \n",
    "        img_paths = []\n",
    "        labels = []\n",
    "        images = []\n",
    "    # for cl_name in self.class_names:\n",
    "    #     img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "    #     for img_name in img_names:\n",
    "    #         img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "    #         hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "    #         labels.append(hot_cl_name)\n",
    "    \n",
    "    #print(input_img_dir)\n",
    "    #print(self.class_names)\n",
    "    \n",
    "        for cl_name in self.class_names:\n",
    "            if cl_name == input_img_dir:\n",
    "                img_names = os.listdir(os.path.join(root_dir, cl_name))\n",
    "\n",
    "\n",
    "\n",
    "                for img_name in img_names:\n",
    "                    img_paths.append(os.path.abspath(os.path.join(root_dir, cl_name, img_name)))\n",
    "                    hot_cl_name = self.get_class_one_hot(cl_name)\n",
    "                    labels.append(hot_cl_name)\n",
    "    \n",
    "        for img_path in img_paths:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            images.append(img)\n",
    "\n",
    "        images = np.array(images)\n",
    "        \n",
    "        return (np.array(images), np.array(labels))\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        label_encoded = self.class_names.index(class_str)\n",
    "    \n",
    "        label_hot = np_utils.to_categorical(label_encoded, len(self.class_names))\n",
    "        label_hot = label_hot\n",
    "        \n",
    "        return label_hot\n",
    "    \n",
    "    def visualizeInterpolation(self, start, end, save=True, nbSteps=10):\n",
    "        print(\"Generating interpolations...\")\n",
    "        \n",
    "        steps = nbSteps\n",
    "        latentStart = start\n",
    "        latentEnd = end\n",
    "        \n",
    "        startImg = self.generator.predict(latentStart)\n",
    "        endImg = self.generator.predict(latentEnd)\n",
    "        \n",
    "        vectors = []\n",
    "        \n",
    "        alphaValues = np.linspace(0, 1, steps)\n",
    "        for alpha in alphaValues:\n",
    "            vector = latentStart * (1 - alpha) + latentEnd * alpha\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        resultLatent = None\n",
    "        resultImage = None\n",
    "        \n",
    "        for i, vec in enumerate(vectors):\n",
    "            gen_img = np.squeeze(self.generator.predict(vec), axis=0)\n",
    "            gen_img = (0.5 * gen_img + 0.5) * 255\n",
    "            interpolatedImage = cv2.cvtColor(gen_img, cv2.COLOR_RGB2BGR)\n",
    "            interpolatedImage = interpolatedImage.astype(np.uint8)\n",
    "            resultImage = interpolatedImage if resultImage is None else np.hstack([resultImage, interpolatedImage])\n",
    "            \n",
    "        return resultImage\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    r, c = 5, 5\n",
    "    check_noise = np.random.uniform(-1, 1, (r * c, 100))\n",
    "    dcgan.train(\n",
    "        iterations=200000,\n",
    "        batch_size=100,\n",
    "        # save_interval=1000,\n",
    "        save_interval=50, ### epoch回数が50の倍数になったときに、generator生成画像を保存\n",
    "        model_interval=5000,\n",
    "        check_noise=check_noise,\n",
    "        r=r,\n",
    "        c=c\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
